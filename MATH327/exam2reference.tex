\documentclass[9pt]{article}
\usepackage{amsthm, amsmath, extsizes, multicol, amsfonts}
\usepackage[normalem]{ulem}
\usepackage[margin=0.25in]{geometry}
\newcommand*\mean[1]{\bar{#1}}
\setlength{\multicolsep}{2pt}
\begin{document}
    \noindent\textbf{Chapter 5} Some Discrete Probability Distributions
    \begin{multicols}{2}
        \noindent\uline{Binomial:} Two possible outcomes from each trial.\\
        \uline{Binomial Distribution:} $b(x;n,p)=\binom{n}{x}p^xq^{n-x}$ 
        x: num of successes. n: num of indep. trials. p: prob. of success.
        q: prob. of failure. $\mu=np$, $\sigma^2=npq$\\
        \uline{Multinomial:} $f(x_1,x_2,...x_k;p_1,p_2,...p_k,n)=\binom{n}{x_1,x_2...x_k}
        p_1^{x_1}p_2^{x_2}...p_k^{x_k}$. $n=\sum_{i=1}^{k}x_i$, and $\sum_{i=1}^{k}p_i=1$\\
        \uline{Hypergeometric:} Choosing successful items.\\
        \uline{Hypergeometric Distribution:} $h(x;N,n,k)=\frac{\binom{k}{x}\binom{N-k}{n-x}}
        {\binom{N}{n}}$. $max(0,n-(N-k))\leq x \leq min(n,k)$. x: num of successes. 
        N: num of items. n: num of selection. k: num of total successes. $\mu=\frac{nk}{N}$,
        $\sigma^2=\frac{N-n}{N-1}n\frac{k}{N}(1-\frac{k}{N})$\\
        \uline{Estimating Hypergeometric using Binomial:} If $n$ is small compared to $N$:
        $(n/N)\leq 0.05$.\\
        \uline{Multivariate:} $f(x_1,x_2,...x_k;a_1,a_2,...a_k,N,n)=\frac{\binom{a_1}{x_1}\binom{a_2}{x_2}
        ...\binom{a_k}{x_k}}{\binom{N}{n}}$. $n=\sum_{i=1}^{k}x_i$, $N=\sum_{i=1}^{k}a_i$.\\
        \uline{Negative Binomial Distribution:} Prob. the kth success will happen by the xth trial.
        $b^*(x;k,p)=\binom{x-1}{k-1}p^kq^{x-k}$. x: trial number. k: success number. p: prob. success.
        q: prob. failure.\\
        \uline{Geometric Distribution:} Prob. the xth trial is the first success. $g(x;p)=pq^{x-1}$.
        x: trial number. p: prob. success. q: prob. failure. $\mu=\frac{1}{p}$. $\sigma^2=\frac{1-p}{p^2}$.\\
        \uline{Poisson Distribution:} Prob. something happens x times in t time. $p(x;\lambda t)=\frac{e^{-\lambda t}(\lambda t)^x}{x!}$.
        x: num of times. $\lambda$: average number of outcomes per time period. t: time interval.\\
        newline
    \end{multicols}
    \noindent\textbf{Chapter 6} Some Continuous Probability Distributions
    \begin{multicols}{2}
        \noindent\uline{Uniform Distribution:} Equal Probability throughout interval. $f(x; A,B)=\frac{1}{B-A}$ if $A\leq x \leq B$,
        0 otherwise. $\mu=\frac{A+B}{2}$, $\sigma^2=\frac{(B-A)^2}{12}$.\\
        \uline{Normal Distribution:} Bell curve. $n(x;\mu,\sigma)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2\sigma^2}(x-\mu)^2}$.
        x: select time. $\mu$: mean. $\sigma$: standard deviation.\\
        \uline{Standard Normal:} A normal distribution where mean is 0 and variance is 1.
        $Z=\frac{X-\mu}{\sigma}$\\
        \uline{Estimating Binomial with Normal:} For large $n$. $P(X\leq x) \approx P(Z\leq \frac{x+0.5-np}{\sqrt{npq}})$\\
        \uline{Gamma Function:} $\Gamma(n) = (n-1)!$. $\Gamma(1)=1$. $\Gamma(1/2)=\sqrt{\pi}$.\\
        \uline{Gamma Distribution:} Wait time, reliability. $f(x;\alpha,\beta)=\frac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{\alpha-1}e^{-\frac{x}{\beta}}$, $x>0$.
        or 0 otherwise. $\mu=\alpha\beta$, $\sigma^2=\alpha\beta^2$.\\
        \uline{Exponential Distribution:} Special case of Gamma where $\alpha=1$. $f(x;\beta)=\frac{1}{\beta}e^{-\frac{x}{\beta}}$ where $x>0$. 0 elsewhere. $\beta$: 
        mean time between failures. $\alpha$: number of events. $\mu=\beta$, $\sigma^2=\beta^2$.\\
        \uline{Chi-Squared Distribution:} Special case of Gamma where $\alpha=v/2$ and $\beta=2$.
        $f(x;v)=\frac{1}{2^{v/2}\Gamma(v/2)}x^{v/2-1}e^{-x/2}$, $x>0$. 0 elsewhere. v: degrees of freedom. $\mu=v$,
        $\sigma^2=2v$.\\
        \uline{Beta Function:} $B(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$, $\alpha,\beta >0$.\\
        \uline{Beta Distribution:} $f(x)=\frac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}$, $0<x<1$. 0 elsewhere.
        $\mu=\frac{\alpha}{\alpha+\beta}$, $\sigma^2=\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$.\\
        \uline{Lognormal Distribution:} if $ln(X)$ is a normal distribution. $f(x;\mu,\sigma)=\frac{1}{x\sigma\sqrt{2\pi}}e^{-1/2\sigma^2(ln(x)-\mu)^2}$, $x\geq 0$.
        0 if $x<0$. mean $ =e^{\mu+\sigma^2/2}$, variance $=e^{2\mu+\sigma^2}(e^{\sigma^2}-1)$.    \end{multicols}
    \noindent\textbf{Chapter 8} Fundamental Sampling Distributions and Data Descriptions
    \begin{multicols}{2}
        \noindent\uline{Central Limit Theorem:} $Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}$ as $n\rightarrow\infty$ is a standard normal distribution.
        $\bar{X}$: mean of random sample size. $\mu$: mean of population. $\sigma$: standard deviation of population.
        n: sample size.\\
        \uline{Difference of Means:} Two populations, samples, means, and variances. $Z=\frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)}{\sqrt{(\sigma^2_1/n_1)+ (\sigma^2_2/n_2)}}$.
        is approx. a standard normal variable.
        $\mu_{\bar{x}_{1}-\bar{x}_{2}}=\mu_1-\mu_2$. $\sigma_{\bar{x}_{1}-\bar{x}_{2}}^{2}=\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}$\\
        \uline{Finding Chi-Squared from Variance:} $\chi^2=\frac{(n-1)S^2}{\sigma^2}=\sum_{i=1}^{n}\frac{(x_1-\bar{x})^2}{\sigma^2}$. Degrees of
        freedom is $v=n-1$, $n$ is sample size.\\
        \uline{t-Distribution:} $T=\frac{Z}{\sqrt{V/v}}$ or $T=\frac{\bar{x}-\mu}{S/\sqrt{n}}$.
        then $h(t)=\frac{\Gamma((v+1)/2)}{\Gamma(v/2)\sqrt{\pi v}}(1+\frac{t^2}{v})$ from $-\infty<t<\infty$.
        Z: standard normal RV. V: chi2 RV. v: degrees of freedom.\\
        \uline{F-Distribution:} $h(f)=\frac{\Gamma((v_1+v_2)/2)(v_1/v_2)^{v_1/2}}{\Gamma(v_1/2)\Gamma(v_2/2)}\cdot
        \frac{f^{(v_1/2)-1}}{(1+v_1f/v_2)^{(v_1+v_2)/2}}$. for $f>0$, 0 if $f\leq 0$. $F=\frac{U/v_1}{V/v_2}$. V,U: indep. RV with chi2 distribution.
        $v_1$, $v_2$: degrees of freedom. $f_{1-\alpha}(v_1,v_2)=\frac{1}{f_{\alpha}(v_2,v_1)}$. $F=\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2}=\frac{\sigma_2^2S_1^2}{\sigma_1^2S_2^2}$\\
        \uline{Normal Q-Q Plot:} Set of observations for normal distribution, will be straight if normal. 1) order data ascending. 2) split normal distribution
        to $n+1$ parts. 3) match the data to the distribution x=data, y=normal. Match smallest with smallest.
    \end{multicols}
    \noindent\textbf{Chapter 9} One- and Two-Sample Estimation Problems
\end{document}